{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR100.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uy0hhB9N7AKt","executionInfo":{"status":"ok","timestamp":1611922808781,"user_tz":-60,"elapsed":23019,"user":{"displayName":"ALEJANDRO MIGUEL PALENCIA BLANCO","photoUrl":"","userId":"12560655080501983919"}},"outputId":"a15daab5-bf85-4aa9-93fc-4031d233dad3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JC6c_TaEFKsw","executionInfo":{"status":"ok","timestamp":1611922810169,"user_tz":-60,"elapsed":24389,"user":{"displayName":"ALEJANDRO MIGUEL PALENCIA BLANCO","photoUrl":"","userId":"12560655080501983919"}},"outputId":"f972c2cc-e26a-4445-e2c9-fb42071e7694"},"source":["%cd /content/drive/My\\ Drive/P_FINAL/entrega"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1HF7BrRwJ4feKbgtGzRUwuiebcM_-b8Js/P_FINAL/entrega\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QRMkpXjvlqrP"},"source":["### Carga y preprocesamiento"]},{"cell_type":"code","metadata":{"id":"aGJKkXfbHaSo"},"source":["import tensorflow as tf\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","CPU = False\n","\n","def transform_data(x_train, x_test, img_size=(64,64), dtype=np.float32):\n","    x_train = np.asarray( [cv.resize(img, img_size) for img in x_train], np.float64 )\n","    x_test = np.asarray( [cv.resize(img, img_size) for img in x_test], np.float64 )\n","    mu = np.mean(x_train, axis=(0,1,2))\n","    sigma = np.std(x_train, axis=(0,1,2))\n","    x_train -= mu\n","    x_train /= sigma\n","    x_test -= mu\n","    x_test /= sigma\n","    x_train = x_train.transpose((0,3,1,2)).astype(dtype)\n","    x_test = x_test.transpose((0,3,1,2)).astype(dtype)\n","    return x_train, x_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hcGw4GKHpIk"},"source":["data = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fsw8hb9iIdN7"},"source":["x_train = data[0][0][:,:,:,::-1]\n","y_train = data[0][1]\n","x_test = data[1][0][:,:,:,::-1]\n","y_test = data[1][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXdTtbgHlxqs"},"source":["x_train, x_test = transform_data(x_train, x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DjUERCsA--G"},"source":["from sklearn.model_selection import train_test_split\n","\n","batch_size = 128\n","x_train, x_val, y_train, y_val = train_test_split(x_train, \n","                                                  y_train, \n","                                                  test_size=0.15, \n","                                                  shuffle=True, \n","                                                  random_state=57)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H28LLFY_lt-A"},"source":["### Instalar Caffe"]},{"cell_type":"code","metadata":{"id":"rk54lb93JLxc"},"source":["if CPU:\n","    !sudo apt install caffe-cpu\n","else:\n","    !sudo apt install caffe-cuda"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SclnhyAZYF9"},"source":["import caffe\n","\n","if not CPU:\n","    caffe.set_mode_gpu()\n","    caffe.set_device(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t8rTiVpvBKlk"},"source":["### Entrenamiento última capa"]},{"cell_type":"code","metadata":{"id":"49iYE01-_Dtu"},"source":["def step_over_chunks(solver, data_chunks, labels_chunks, img_shape):\n","    for dchunk, lchunk in zip(data_chunks, labels_chunks):\n","        new_shape = (len(dchunk),) + img_shape\n","        if solver.net.blobs['data'].data.shape != new_shape:\n","            solver.net.blobs['data'].reshape(*new_shape)\n","            solver.net.blobs['label'].reshape(len(dchunk))\n","        for i in range(len(dchunk)):\n","            solver.net.blobs['data'].data[i] = dchunk[i]\n","            solver.net.blobs['label'].data[i] = lchunk[i]\n","        solver.step(1)\n","\n","def test_net(test_net, x_test, y_test, batch_size):\n","    test_data_chunks = [ x_test[x:x+batch_size] for x in range(0, len(x_test), batch_size) ]\n","    test_labels_chunks = [ np.squeeze(y_test[y:y+batch_size]) for y in range(0, len(y_test), batch_size) ]\n","    loss_sum = 0\n","    accuracy = 0\n","\n","    for dchunk, lchunk in zip(test_data_chunks, test_labels_chunks):\n","        new_shape = (len(dchunk),) + x_test[0].shape\n","        if test_net.blobs['data'].data.shape != new_shape:\n","            test_net.blobs['data'].reshape(*new_shape)\n","            test_net.blobs['label'].reshape(len(dchunk))\n","        test_net.blobs['data'].data[:] = dchunk[:]\n","        test_net.blobs['label'].data[:] = lchunk[:]\n","\n","        test_net.forward()\n","        loss_sum += test_net.blobs['loss'].data\n","        accuracy += test_net.blobs['accuracy'].data\n","\n","    return loss_sum/len(test_data_chunks), accuracy/len(test_data_chunks)\n","\n","def fit(solver, x_train, y_train, x_val, y_val, niter, batch_size, patience=5, epsilon=0.0001):\n","    train_loss, val_loss = np.zeros(niter), np.zeros(niter)\n","\n","    data_chunks = [ x_train[x:x+batch_size] for x in range(0, len(x_train), batch_size) ]\n","    labels_chunks = [ y_train[y:y+batch_size] for y in range(0, len(y_train), batch_size) ]\n","\n","    final_it = niter-1\n","    best_loss = float(\"inf\")\n","    worse_loss_counter = 0\n","\n","    for it in range(niter):\n","        step_over_chunks(solver, data_chunks, labels_chunks, x_train[0].shape)\n","        train_loss[it] = solver.net.blobs['loss'].data\n","        val_loss[it], _ = test_net(solver.test_nets[0], x_val, y_val, batch_size)\n","        print('iter {}, loss={}, val_loss={}'.format(it, train_loss[it], val_loss[it]))\n","\n","        if val_loss[it] < best_loss - epsilon:\n","            best_loss = val_loss[it]\n","            worse_loss_counter = 0\n","        else:\n","            worse_loss_counter += 1\n","            if worse_loss_counter > patience:\n","                final_it = it\n","                break\n","    \n","    return train_loss[0:final_it+1], val_loss[0:final_it+1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOly5VD2N80M"},"source":["# Entrenamiento última capa\n","\n","solver_cifar100 = caffe.get_solver('./model_cifar100/solver_cifar100.prototxt')\n","solver_cifar100.net.copy_from('./model_cfn_jps/cfn_jps.caffemodel')\n","\n","train_loss, val_loss = fit(solver_cifar100, x_train, y_train, x_val, y_val, 200, batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_AA4CzewR4XD"},"source":["# Comprobar la precisión del modelo final\n","\n","_, accuracy = test_net(solver_cifar100.test_nets[0], x_test, y_test, batch_size)\n","print(\"Precisión en test: {}\".format(accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVE1G-YRSEn9"},"source":["# Guardar los pesos del modelo\n","\n","solver_cifar100.net.save('./model_cifar100/cifar100.caffemodel')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRzFK2KzTCCB"},"source":["# Gráfica train-loss, val-loss\n","\n","_, ax1 = plt.subplots()\n","ax1.plot(np.arange(len(train_loss)), train_loss, label='Train loss')\n","ax1.plot(np.arange(len(val_loss)), val_loss, label='Validation loss')\n","ax1.set_xlabel('Epochs')\n","ax1.legend(loc='best')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NCEZyQuEBRRu"},"source":["### Ajuste fino"]},{"cell_type":"code","metadata":{"id":"H71S1K0MX0vp"},"source":["# Fine Tuning\n","\n","solver_cifar100_ft = caffe.get_solver('./model_cifar100/solver_cifar100_fine_tuning.prototxt')\n","solver_cifar100_ft.net.copy_from('./model_cifar100/cifar100.caffemodel')\n","\n","train_loss_ft, val_loss_ft = fit(solver_cifar100_ft, x_train, y_train, x_val, y_val, 50, batch_size, patience=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGJPg373d63P"},"source":["# Comprobar la precisión del modelo final\n","\n","_, accuracy = test_net(solver_cifar100_ft.test_nets[0], x_test, y_test, batch_size)\n","print(\"Precisión en test: {}\".format(accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_CXacX-YESF"},"source":["# Guardar los pesos del modelo\n","\n","solver_cifar100_ft.net.save('./cifar100_fine_tuning.caffemodel')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3q7SsPtfeEd1"},"source":["# Gráfica train-loss, val-loss\n","\n","_, ax1 = plt.subplots()\n","ax1.plot(np.arange(len(train_loss_ft)), train_loss_ft, label='Train loss')\n","ax1.plot(np.arange(len(val_loss_ft)), val_loss_ft, label='Validation loss')\n","ax1.set_xlabel('Epochs')\n","ax1.legend(loc='best')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kg_ZELdkAfQV"},"source":["### Filtros aprendidos"]},{"cell_type":"code","metadata":{"id":"Q-M6xU6jEuPx"},"source":["def vis_square(data):\n","    \"\"\"Take an array of shape (n, height, width) or (n, height, width, 3)\n","       and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\"\"\"\n","    \n","    # normalize data for display\n","    data = (data - data.min()) / (data.max() - data.min())\n","    \n","    # force the number of filters to be square\n","    n = int(np.ceil(np.sqrt(data.shape[0])))\n","    padding = (((0, n ** 2 - data.shape[0]),\n","               (0, 1), (0, 1))                 # add some space between filters\n","               + ((0, 0),) * (data.ndim - 3))  # don't pad the last dimension (if there is one)\n","    data = np.pad(data, padding, mode='constant', constant_values=1)  # pad with ones (white)\n","    \n","    # tile the filters into an image\n","    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n","    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n","    \n","    plt.imshow(data, cmap='gray'); plt.axis('off')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qViX3f3MsU0Q"},"source":["[enlace de la función vis_square](https://github.com/arundasan91/Deep-Learning-with-Caffe/blob/master/Deep-Neural-Network-with-Caffe/Deep%20Neural%20Network%20with%20Caffe.md)"]},{"cell_type":"code","metadata":{"id":"7F_qyOQQoeBc"},"source":["# Cargar las dos versiones del modelo (solo con entrenamiento en la última capa y con fine tuning)\n","\n","model_cifar100 = caffe.Net('./model_cifar100/model_cifar100.prototxt','./model_cifar100/cifar100.caffemodel',caffe.TEST)\n","model_cifar100_ft = caffe.Net('./model_cifar100/model_cifar100_fine_tuning.prototxt','./model_cifar100/cifar100_fine_tuning.caffemodel',caffe.TEST)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcmXf4hVFbQQ"},"source":["# Obtener los filtros de la primera capa convolucional\n","\n","filters = model_cifar100.params['conv1_s1'][0].data\n","vis_square(filters.transpose(0, 2, 3, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KxS_x4Vpk4t"},"source":["# Obtener los filtros de la primera capa convolucional\n","\n","filters = model_cifar100_ft.params['conv1_s1'][0].data\n","vis_square(filters.transpose(0, 2, 3, 1))"],"execution_count":null,"outputs":[]}]}